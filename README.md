# neural-networks-from-scratch

Building neural networks from scratch. I have tried doing this a year ago, but my efforts were just writing simple feedfoward neural networks for one specific application. This time I want to be slightly more ambitious, and write a more diverse variety of neural networks that can run on the GPU.

These are some plans:

1. Write matrix class that performs matrix operations (matrix.cuh)
2. Write the simplest functioning layer, the dense layer. (dense.cuh)
3. Write activation functions.
4. Write simple optimizers (SGD lol, with momentum maybe).
5. Write something that is able to use store and use an entire model consisting multiple layers.
6. Write 2D convolutional layers.
7. Write batch-normalization, dropout, pooling, and other layers.

...

Maybe I can adapt this to train alphazero-guerzhoy faster. Just maybe. We will see if I *ever* get here.
